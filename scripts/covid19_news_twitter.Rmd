---
title: "COVID19 Africa response"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    html_preview: false
    toc: true
    toc_depth: 2
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath("~/Documents/freightwaves/Africa-covid19-response")) 
library(rtweet)
library(tidyverse)
library(rvest)
theme_set(theme_bw(base_size=20))
```

Load csv of twitter handles,

```{r}
news_sites <- read_csv('data/africa_news_sites.csv', na = c("null",""," "))
print(news_sites)
```

To search the handles we need to strip the "@", look up user, and collect the data,

```{r, warning=FALSE, message='FALSE'}
news_tweets <- news_sites %>%
  mutate(screen_name = str_remove(twitter_handle,"@")) %>% # remove @
  drop_na(screen_name) %>% # remove rows without handles
  pull(screen_name) %>% # extract screen name column
  lookup_users() %>% # lookup user information
  tweets_data() %>% # load tweets
  filter(created_at >= '2019-12-01') %>% # filter for recent tweets
  select(created_at,screen_name,text,favorite_count,retweet_count,
         hashtags, linked_url=urls_expanded_url) %>% # select specific columns
  unnest(linked_url) # convert url from list to column

head(news_tweets)
```

Download text from one webpage,

```{r}
webpage <- read_html(news_tweets$linked_url[3]) %>%
   html_nodes(xpath='//*[@id="root"]/div/main/div[3]/div/div[6]') %>%      
        html_text() 

print(webpage)
```






